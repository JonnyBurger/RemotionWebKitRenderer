{"version":3,"file":"618.bundle.js","mappings":";;;;;;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAGA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AAEA;AAEA;AAEA;AAEA;AAEA;AAEA;AAEA;AAEA;AAEA;AAEA;AACA;AAEA;AAAA;AAGA;AAAA;AAEA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AAAA;AAEA;AACA;AACA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AAAA;AAAA;AAGA;AACA;AACA;AAAA;AAAA;;;;;;;;;AC3FA;AACA;AACA;AACA;AACA;AAAA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAEA;AAAA;AAEA;;;;;;;;;ACbA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AAAA;AAEA;AACA;AACA;AAAA;AAEA;AACA;AACA;AAAA;AAEA;;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAAA;AAEA;AAAA;AAGA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AAAA;AAEA;AAAA;AAEA;;;;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AAAA;AAEA;AACA;AAAA;AAEA;AACA;AACA;AAAA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAEA;;;;;;;;;AC3BA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;;;;;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAGA;AAAA;AAEA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AAAA;AAEA;;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AAAA;AAEA;AAAA;AAEA;AAAA;AAEA;AAAA;AAEA;;;;;;;;;AC3BA;AACA;AACA;AACA;;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAGA;AACA;AAOA;AAAA;AAEA;AAAA;AAAA;AAGA;AACA;AACA;AAAA;AAEA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAGA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAEA;AACA;AAAA;AAEA;;;;;;;;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AAAA;AAEA;AACA;AAAA;AAAA;AASA;AACA;AAAA;AAEA;AAIA;AACA;;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AAAA;AAEA;AACA;AAAA;AAAA;AAGA;AACA;AAAA;AAEA;;;;;;;;;ACjDA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AAAA;AAEA;AAAA;AAEA;AACA;AACA;AAAA;AAEA;AACA;AAAA;AAEA;;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAAA;AACA;AACA;AAAA;AAAA;AAIA;;;;;;;;;ACfA;AACA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AAAA;AAEA;AAAA;AAEA;AAAA;AACA;AAAA;AAEA;AACA;AAAA;AAAA;AAAA;AAEA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AACA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;;;;;;;;;AC/BA;AACA;AACA;AACA;;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAGA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAEA;AACA;AAAA;AAEA;AACA;AACA;AACA;AAKA;AACA;AACA;AAAA;AAAA;AAAA;AAIA;AACA;AAAA;AAEA;AAAA;AACA;AACA;AAAA;AAEA;AACA;AAAA;AAEA;AAEA;AAAA;AAAA;AAAA;AAIA;AAAA;AAEA;;;;;;;;;ACvDA;;;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;AAGA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AAAA;AAEA;AACA;AAAA;AAEA;AAAA;AAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAGA;AAAA;AACA;AACA;AAAA;AAEA;AAAA;AACA;AACA;AACA;AAEA;AACA;AAAA;AAEA;AACA;AAGA;AAAA;AAEA;AAAA;AAGA","sources":["../media-utils/dist/audio-buffer/audio-buffer-to-wav.js","../media-utils/dist/audio-buffer/audio-url-helpers.js","../media-utils/dist/fft/complex.js","../media-utils/dist/fft/exponent.js","../media-utils/dist/fft/fft.js","../media-utils/dist/fft/get-visualization.js","../media-utils/dist/fft/mag.js","../media-utils/dist/fft/max-value-cached.js","../media-utils/dist/fft/smoothing.js","../media-utils/dist/fft/to-int-16.js","../media-utils/dist/get-audio-data.js","../media-utils/dist/get-audio-duration-in-seconds.js","../media-utils/dist/get-video-metadata.js","../media-utils/dist/get-wave-form-samples.js","../media-utils/dist/get-waveform-portion.js","../media-utils/dist/index.js","../media-utils/dist/is-remote-asset.js","../media-utils/dist/p-limit.js","../media-utils/dist/types.js","../media-utils/dist/use-audio-data.js","../media-utils/dist/visualize-audio.js"],"sourcesContent":["\"use strict\";\n/**\n * Inlined from https://github.com/Jam3/audiobuffer-to-wav/commit/2272eb09bd46a05e50a6d684d908aa6f13c58f63#diff-e727e4bdf3657fd1d798edcd6b099d6e092f8573cba266154583a746bba0f346\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.audioBufferToWav = void 0;\nfunction audioBufferToWav(buffer, opt) {\n    const numChannels = buffer.numberOfChannels;\n    const { sampleRate } = buffer;\n    const format = opt.float32 ? 3 : 1;\n    const bitDepth = format === 3 ? 32 : 16;\n    let result;\n    if (numChannels === 2) {\n        result = interleave(buffer.getChannelData(0), buffer.getChannelData(1));\n    }\n    else {\n        result = buffer.getChannelData(0);\n    }\n    return encodeWAV({\n        samples: result,\n        format,\n        sampleRate,\n        numChannels,\n        bitDepth,\n    });\n}\nexports.audioBufferToWav = audioBufferToWav;\nfunction encodeWAV({ samples, format, sampleRate, numChannels, bitDepth, }) {\n    const bytesPerSample = bitDepth / 8;\n    const blockAlign = numChannels * bytesPerSample;\n    const buffer = new ArrayBuffer(44 + samples.length * bytesPerSample);\n    const view = new DataView(buffer);\n    /* RIFF identifier */\n    writeString(view, 0, 'RIFF');\n    /* RIFF chunk length */\n    view.setUint32(4, 36 + samples.length * bytesPerSample, true);\n    /* RIFF type */\n    writeString(view, 8, 'WAVE');\n    /* format chunk identifier */\n    writeString(view, 12, 'fmt ');\n    /* format chunk length */\n    view.setUint32(16, 16, true);\n    /* sample format (raw) */\n    view.setUint16(20, format, true);\n    /* channel count */\n    view.setUint16(22, numChannels, true);\n    /* sample rate */\n    view.setUint32(24, sampleRate, true);\n    /* byte rate (sample rate * block align) */\n    view.setUint32(28, sampleRate * blockAlign, true);\n    /* block align (channel count * bytes per sample) */\n    view.setUint16(32, blockAlign, true);\n    /* bits per sample */\n    view.setUint16(34, bitDepth, true);\n    /* data chunk identifier */\n    writeString(view, 36, 'data');\n    /* data chunk length */\n    view.setUint32(40, samples.length * bytesPerSample, true);\n    if (format === 1) {\n        // Raw PCM\n        floatTo16BitPCM(view, 44, samples);\n    }\n    else {\n        writeFloat32(view, 44, samples);\n    }\n    return buffer;\n}\nfunction interleave(inputL, inputR) {\n    const length = inputL.length + inputR.length;\n    const result = new Float32Array(length);\n    let index = 0;\n    let inputIndex = 0;\n    while (index < length) {\n        result[index++] = inputL[inputIndex];\n        result[index++] = inputR[inputIndex];\n        inputIndex++;\n    }\n    return result;\n}\nfunction writeFloat32(output, offset, input) {\n    for (let i = 0; i < input.length; i++, offset += 4) {\n        output.setFloat32(offset, input[i], true);\n    }\n}\nfunction floatTo16BitPCM(output, offset, input) {\n    for (let i = 0; i < input.length; i++, offset += 2) {\n        const s = Math.max(-1, Math.min(1, input[i]));\n        output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);\n    }\n}\nfunction writeString(view, offset, string) {\n    for (let i = 0; i < string.length; i++) {\n        view.setUint8(offset + i, string.charCodeAt(i));\n    }\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.audioBufferToDataUrl = void 0;\nconst audio_buffer_to_wav_1 = require(\"./audio-buffer-to-wav\");\nconst audioBufferToDataUrl = (buffer) => {\n    const wavAsArrayBuffer = (0, audio_buffer_to_wav_1.audioBufferToWav)(buffer, {\n        float32: true,\n    });\n    let binary = '';\n    const bytes = new Uint8Array(wavAsArrayBuffer);\n    const len = bytes.byteLength;\n    for (let i = 0; i < len; i++) {\n        binary += String.fromCharCode(bytes[i]);\n    }\n    return 'data:audio/wav;base64,' + window.btoa(binary);\n};\nexports.audioBufferToDataUrl = audioBufferToDataUrl;\n","\"use strict\";\n// Adapted from node-fft project by Joshua Wong and Ben Bryan\n// https://github.com/vail-systems/node-fft\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.complexMagnitude = exports.complexMultiply = exports.complexSubtract = exports.complexAdd = void 0;\nconst complexAdd = function (a, b) {\n    return [a[0] + b[0], a[1] + b[1]];\n};\nexports.complexAdd = complexAdd;\nconst complexSubtract = function (a, b) {\n    return [a[0] - b[0], a[1] - b[1]];\n};\nexports.complexSubtract = complexSubtract;\nconst complexMultiply = function (a, b) {\n    return [a[0] * b[0] - a[1] * b[1], a[0] * b[1] + a[1] * b[0]];\n};\nexports.complexMultiply = complexMultiply;\nconst complexMagnitude = function (c) {\n    return Math.sqrt(c[0] * c[0] + c[1] * c[1]);\n};\nexports.complexMagnitude = complexMagnitude;\n","\"use strict\";\n// Adapted from node-fft project by Joshua Wong and Ben Bryan\n// https://github.com/vail-systems/node-fft\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.exponent = void 0;\nconst mapExponent = {};\nconst exponent = function (k, N) {\n    const x = -2 * Math.PI * (k / N);\n    mapExponent[N] = mapExponent[N] || {};\n    mapExponent[N][k] = mapExponent[N][k] || [Math.cos(x), Math.sin(x)]; // [Real, Imaginary]\n    return mapExponent[N][k];\n};\nexports.exponent = exponent;\n","\"use strict\";\n// Adapted from node-fft project by Joshua Wong and Ben Bryan\n// https://github.com/vail-systems/node-fft\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.fft = void 0;\nconst complex_1 = require(\"./complex\");\nconst exponent_1 = require(\"./exponent\");\nconst fft = function (vector) {\n    const X = [];\n    const N = vector.length;\n    // Base case is X = x + 0i since our input is assumed to be real only.\n    if (N === 1) {\n        if (Array.isArray(vector[0])) {\n            // If input vector contains complex numbers\n            return [[vector[0][0], vector[0][1]]];\n        }\n        return [[vector[0], 0]];\n    }\n    // Recurse: all even samples\n    const X_evens = (0, exports.fft)(vector.filter((_, ix) => ix % 2 === 0));\n    // Recurse: all odd samples\n    const X_odds = (0, exports.fft)(vector.filter((__, ix) => ix % 2 === 1));\n    // Now, perform N/2 operations!\n    for (let k = 0; k < N / 2; k++) {\n        // t is a complex number!\n        const t = X_evens[k];\n        const e = (0, complex_1.complexMultiply)((0, exponent_1.exponent)(k, N), X_odds[k]);\n        X[k] = (0, complex_1.complexAdd)(t, e);\n        X[k + N / 2] = (0, complex_1.complexSubtract)(t, e);\n    }\n    return X;\n};\nexports.fft = fft;\n","\"use strict\";\n// Adapted from node-fft project by Joshua Wong and Ben Bryan\n// https://github.com/vail-systems/node-fft\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getVisualization = void 0;\nconst fft_1 = require(\"./fft\");\nconst mag_1 = require(\"./mag\");\nconst smoothing_1 = require(\"./smoothing\");\nconst to_int_16_1 = require(\"./to-int-16\");\nconst getVisualization = ({ sampleSize, data, sampleRate, frame, fps, maxInt, }) => {\n    const isPowerOfTwo = sampleSize > 0 && (sampleSize & (sampleSize - 1)) === 0;\n    if (!isPowerOfTwo) {\n        throw new TypeError(`The argument \"bars\" must be a power of two. For example: 64, 128. Got instead: ${sampleSize}`);\n    }\n    if (!fps) {\n        throw new TypeError('The argument \"fps\" was not provided');\n    }\n    if (data.length < sampleSize) {\n        throw new TypeError('Audio data is not big enough to provide ' + sampleSize + ' bars.');\n    }\n    const start = Math.floor((frame / fps) * sampleRate);\n    const actualStart = Math.max(0, start - sampleSize / 2);\n    const ints = new Int16Array({\n        length: sampleSize,\n    });\n    ints.set(data.subarray(actualStart, actualStart + sampleSize).map((x) => (0, to_int_16_1.toInt16)(x)));\n    const phasors = (0, fft_1.fft)(ints);\n    const magnitudes = (0, mag_1.fftMag)(phasors).map((p) => p);\n    return (0, smoothing_1.smoothen)(magnitudes).map((m) => m / (sampleSize / 2) / maxInt);\n};\nexports.getVisualization = getVisualization;\n","\"use strict\";\n// Adapted from node-fft project by Joshua Wong and Ben Bryan\n// https://github.com/vail-systems/node-fft\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.fftMag = void 0;\nconst complex_1 = require(\"./complex\");\nconst fftMag = function (fftBins) {\n    const ret = fftBins.map((f) => (0, complex_1.complexMagnitude)(f));\n    return ret.slice(0, ret.length / 2);\n};\nexports.fftMag = fftMag;\n","\"use strict\";\n// Adapted from node-fft project by Joshua Wong and Ben Bryan\n// https://github.com/vail-systems/node-fft\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getMaxPossibleMagnitude = void 0;\nconst to_int_16_1 = require(\"./to-int-16\");\nconst getMax = (array) => {\n    let max = 0;\n    for (let i = 0; i < array.length; i++) {\n        const val = array[i];\n        if (val > max) {\n            max = val;\n        }\n    }\n    return max;\n};\nconst cache = {};\nconst getMaxPossibleMagnitude = (metadata) => {\n    if (cache[metadata.resultId]) {\n        return cache[metadata.resultId];\n    }\n    const result = (0, to_int_16_1.toInt16)(getMax(metadata.channelWaveforms[0]));\n    cache[metadata.resultId] = result;\n    return result;\n};\nexports.getMaxPossibleMagnitude = getMaxPossibleMagnitude;\n","\"use strict\";\n// Adapted from node-fft project by Joshua Wong and Ben Bryan\n// https://github.com/vail-systems/node-fft\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.smoothen = void 0;\nconst smoothingPasses = 3;\nconst smoothingPoints = 3;\nconst smoothen = function (array) {\n    let lastArray = array;\n    const newArr = [];\n    for (let pass = 0; pass < smoothingPasses; pass++) {\n        const sidePoints = Math.floor(smoothingPoints / 2); // our window is centered so this is both nL and nR\n        const cn = 1 / (2 * sidePoints + 1); // constant\n        for (let i = 0; i < sidePoints; i++) {\n            newArr[i] = lastArray[i];\n            newArr[lastArray.length - i - 1] = lastArray[lastArray.length - i - 1];\n        }\n        for (let i = sidePoints; i < lastArray.length - sidePoints; i++) {\n            let sum = 0;\n            for (let n = -sidePoints; n <= sidePoints; n++) {\n                sum += cn * lastArray[i + n] + n;\n            }\n            newArr[i] = sum;\n        }\n        lastArray = newArr;\n    }\n    return newArr;\n};\nexports.smoothen = smoothen;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toInt16 = void 0;\nconst toInt16 = (x) => (x > 0 ? x * 0x7fff : x * 0x8000);\nexports.toInt16 = toInt16;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getAudioData = void 0;\nconst is_remote_asset_1 = require(\"./is-remote-asset\");\nconst p_limit_1 = require(\"./p-limit\");\nconst metadataCache = {};\nconst limit = (0, p_limit_1.pLimit)(3);\nconst fetchWithCorsCatch = async (src) => {\n    try {\n        const response = await fetch(src);\n        return response;\n    }\n    catch (err) {\n        const error = err;\n        if (\n        // Chrome\n        error.message.includes('Failed to fetch') ||\n            // Safari\n            error.message.includes('Load failed') ||\n            // Firefox\n            error.message.includes('NetworkError when attempting to fetch resource')) {\n            throw new TypeError(`Failed to read from ${src}: ${error.message}. Does the resource support CORS?`);\n        }\n        throw err;\n    }\n};\nconst fn = async (src) => {\n    if (metadataCache[src]) {\n        return metadataCache[src];\n    }\n    if (typeof document === 'undefined') {\n        throw new Error('getAudioData() is only available in the browser.');\n    }\n    const audioContext = new AudioContext();\n    const response = await fetchWithCorsCatch(src);\n    const arrayBuffer = await response.arrayBuffer();\n    const wave = await audioContext.decodeAudioData(arrayBuffer);\n    const channelWaveforms = new Array(wave.numberOfChannels)\n        .fill(true)\n        .map((_, channel) => {\n        return wave.getChannelData(channel);\n    });\n    const metadata = {\n        channelWaveforms,\n        sampleRate: audioContext.sampleRate,\n        durationInSeconds: wave.duration,\n        numberOfChannels: wave.numberOfChannels,\n        resultId: String(Math.random()),\n        isRemote: (0, is_remote_asset_1.isRemoteAsset)(src),\n    };\n    metadataCache[src] = metadata;\n    return metadata;\n};\nconst getAudioData = (src) => {\n    return limit(fn, src);\n};\nexports.getAudioData = getAudioData;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getAudioDuration = exports.getAudioDurationInSeconds = void 0;\nconst p_limit_1 = require(\"./p-limit\");\nconst limit = (0, p_limit_1.pLimit)(3);\nconst metadataCache = {};\nconst fn = (src) => {\n    if (metadataCache[src]) {\n        return Promise.resolve(metadataCache[src]);\n    }\n    if (typeof document === 'undefined') {\n        throw new Error('getAudioDuration() is only available in the browser.');\n    }\n    const audio = document.createElement('audio');\n    audio.src = src;\n    return new Promise((resolve, reject) => {\n        const onError = () => {\n            reject(audio.error);\n            cleanup();\n        };\n        const onLoadedMetadata = () => {\n            metadataCache[src] = audio.duration;\n            resolve(audio.duration);\n            cleanup();\n        };\n        const cleanup = () => {\n            audio.removeEventListener('loadedmetadata', onLoadedMetadata);\n            audio.removeEventListener('error', onError);\n            audio.remove();\n        };\n        audio.addEventListener('loadedmetadata', onLoadedMetadata, { once: true });\n        audio.addEventListener('error', onError, { once: true });\n    });\n};\n/**\n * Get the audio file passed in parameter duration in seconds\n * @async\n * @param src path to the audio file\n * @return {number} duration of the audio file in seconds\n */\nconst getAudioDurationInSeconds = (src) => {\n    return limit(fn, src);\n};\nexports.getAudioDurationInSeconds = getAudioDurationInSeconds;\n/**\n * @deprecated Renamed to `getAudioDurationInSeconds`\n */\nconst getAudioDuration = (src) => (0, exports.getAudioDurationInSeconds)(src);\nexports.getAudioDuration = getAudioDuration;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getVideoMetadata = void 0;\nconst is_remote_asset_1 = require(\"./is-remote-asset\");\nconst p_limit_1 = require(\"./p-limit\");\nconst cache = {};\nconst limit = (0, p_limit_1.pLimit)(3);\nconst fn = (src) => {\n    if (cache[src]) {\n        return Promise.resolve(cache[src]);\n    }\n    if (typeof document === 'undefined') {\n        throw new Error('getVideoMetadata() is only available in the browser.');\n    }\n    const video = document.createElement('video');\n    video.src = src;\n    return new Promise((resolve, reject) => {\n        const onError = () => {\n            reject(video.error);\n            cleanup();\n        };\n        const onLoadedMetadata = () => {\n            const pixels = video.videoHeight * video.videoWidth;\n            if (pixels === 0) {\n                reject(new Error('Unable to determine video metadata'));\n                return;\n            }\n            const metadata = {\n                durationInSeconds: video.duration,\n                width: video.videoWidth,\n                height: video.videoHeight,\n                aspectRatio: video.videoWidth / video.videoHeight,\n                isRemote: (0, is_remote_asset_1.isRemoteAsset)(src),\n            };\n            resolve(metadata);\n            cache[src] = metadata;\n            cleanup();\n        };\n        const cleanup = () => {\n            video.removeEventListener('loadedmetadata', onLoadedMetadata);\n            video.removeEventListener('error', onError);\n            video.remove();\n        };\n        video.addEventListener('loadedmetadata', onLoadedMetadata, { once: true });\n        video.addEventListener('error', onError, { once: true });\n    });\n};\nconst getVideoMetadata = (src) => {\n    return limit(fn, src);\n};\nexports.getVideoMetadata = getVideoMetadata;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getWaveformSamples = void 0;\nconst filterData = (audioBuffer, samples) => {\n    const blockSize = Math.floor(audioBuffer.length / samples); // the number of samples in each subdivision\n    if (blockSize === 0) {\n        return [];\n    }\n    const filteredData = [];\n    for (let i = 0; i < samples; i++) {\n        const blockStart = blockSize * i; // the location of the first sample in the block\n        let sum = 0;\n        for (let j = 0; j < blockSize; j++) {\n            sum += Math.abs(audioBuffer[blockStart + j]); // find the sum of all the samples in the block\n        }\n        filteredData.push(sum / blockSize); // divide the sum by the block size to get the average\n    }\n    return filteredData;\n};\nconst normalizeData = (filteredData) => {\n    const multiplier = Math.max(...filteredData) ** -1;\n    return filteredData.map((n) => n * multiplier);\n};\nconst getWaveformSamples = (waveform, sampleAmount) => {\n    return normalizeData(filterData(waveform, sampleAmount));\n};\nexports.getWaveformSamples = getWaveformSamples;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getWaveformPortion = void 0;\nconst get_wave_form_samples_1 = require(\"./get-wave-form-samples\");\nconst getWaveformPortion = ({ audioData, startTimeInSeconds, durationInSeconds, numberOfSamples, }) => {\n    const startSample = Math.floor((startTimeInSeconds / audioData.durationInSeconds) *\n        audioData.channelWaveforms[0].length);\n    const endSample = Math.floor(((startTimeInSeconds + durationInSeconds) / audioData.durationInSeconds) *\n        audioData.channelWaveforms[0].length);\n    return (0, get_wave_form_samples_1.getWaveformSamples)(audioData.channelWaveforms[0].slice(startSample, endSample), numberOfSamples).map((w, i) => {\n        return {\n            index: i,\n            amplitude: w,\n        };\n    });\n};\nexports.getWaveformPortion = getWaveformPortion;\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.visualizeAudio = exports.useAudioData = exports.getWaveformPortion = exports.getVideoMetadata = exports.getAudioDurationInSeconds = exports.getAudioDuration = exports.getAudioData = exports.audioBufferToDataUrl = void 0;\nvar audio_url_helpers_1 = require(\"./audio-buffer/audio-url-helpers\");\nObject.defineProperty(exports, \"audioBufferToDataUrl\", { enumerable: true, get: function () { return audio_url_helpers_1.audioBufferToDataUrl; } });\nvar get_audio_data_1 = require(\"./get-audio-data\");\nObject.defineProperty(exports, \"getAudioData\", { enumerable: true, get: function () { return get_audio_data_1.getAudioData; } });\nvar get_audio_duration_in_seconds_1 = require(\"./get-audio-duration-in-seconds\");\nObject.defineProperty(exports, \"getAudioDuration\", { enumerable: true, get: function () { return get_audio_duration_in_seconds_1.getAudioDuration; } });\nObject.defineProperty(exports, \"getAudioDurationInSeconds\", { enumerable: true, get: function () { return get_audio_duration_in_seconds_1.getAudioDurationInSeconds; } });\nvar get_video_metadata_1 = require(\"./get-video-metadata\");\nObject.defineProperty(exports, \"getVideoMetadata\", { enumerable: true, get: function () { return get_video_metadata_1.getVideoMetadata; } });\nvar get_waveform_portion_1 = require(\"./get-waveform-portion\");\nObject.defineProperty(exports, \"getWaveformPortion\", { enumerable: true, get: function () { return get_waveform_portion_1.getWaveformPortion; } });\n__exportStar(require(\"./types\"), exports);\nvar use_audio_data_1 = require(\"./use-audio-data\");\nObject.defineProperty(exports, \"useAudioData\", { enumerable: true, get: function () { return use_audio_data_1.useAudioData; } });\nvar visualize_audio_1 = require(\"./visualize-audio\");\nObject.defineProperty(exports, \"visualizeAudio\", { enumerable: true, get: function () { return visualize_audio_1.visualizeAudio; } });\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.isRemoteAsset = void 0;\nconst isRemoteAsset = (asset) => !asset.startsWith(window.location.origin) && !asset.startsWith('data');\nexports.isRemoteAsset = isRemoteAsset;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.pLimit = void 0;\nconst pLimit = (concurrency) => {\n    const queue = [];\n    let activeCount = 0;\n    const next = () => {\n        var _a;\n        activeCount--;\n        if (queue.length > 0) {\n            (_a = queue.shift()) === null || _a === void 0 ? void 0 : _a();\n        }\n    };\n    const run = async (fn, resolve, ...args) => {\n        activeCount++;\n        // eslint-disable-next-line require-await\n        const result = (async () => fn(...args))();\n        resolve(result);\n        try {\n            await result;\n        }\n        catch (_a) { }\n        next();\n    };\n    const enqueue = (fn, resolve, ...args) => {\n        queue.push(() => run(fn, resolve, ...args));\n        (async () => {\n            var _a;\n            // This function needs to wait until the next microtask before comparing\n            // `activeCount` to `concurrency`, because `activeCount` is updated asynchronously\n            // when the run function is dequeued and called. The comparison in the if-statement\n            // needs to happen asynchronously as well to get an up-to-date value for `activeCount`.\n            await Promise.resolve();\n            if (activeCount < concurrency && queue.length > 0) {\n                (_a = queue.shift()) === null || _a === void 0 ? void 0 : _a();\n            }\n        })();\n    };\n    const generator = (fn, ...args) => new Promise((resolve) => {\n        enqueue(fn, resolve, ...args);\n    });\n    Object.defineProperties(generator, {\n        activeCount: {\n            get: () => activeCount,\n        },\n        pendingCount: {\n            get: () => queue.length,\n        },\n        clearQueue: {\n            value: () => {\n                queue.length = 0;\n            },\n        },\n    });\n    return generator;\n};\nexports.pLimit = pLimit;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.useAudioData = void 0;\nconst react_1 = require(\"react\");\nconst remotion_1 = require(\"remotion\");\nconst get_audio_data_1 = require(\"./get-audio-data\");\nconst useAudioData = (src) => {\n    if (!src) {\n        throw new TypeError(\"useAudioData requires a 'src' parameter\");\n    }\n    const mountState = (0, react_1.useRef)({ isMounted: true });\n    (0, react_1.useEffect)(() => {\n        const { current } = mountState;\n        current.isMounted = true;\n        return () => {\n            current.isMounted = false;\n        };\n    }, []);\n    const [metadata, setMetadata] = (0, react_1.useState)(null);\n    const fetchMetadata = (0, react_1.useCallback)(async () => {\n        const handle = (0, remotion_1.delayRender)(`Waiting for audio metadata with src=\"${src}\" to be loaded`);\n        const data = await (0, get_audio_data_1.getAudioData)(src);\n        if (mountState.current.isMounted) {\n            setMetadata(data);\n        }\n        (0, remotion_1.continueRender)(handle);\n    }, [src]);\n    (0, react_1.useEffect)(() => {\n        fetchMetadata();\n    }, [fetchMetadata]);\n    return metadata;\n};\nexports.useAudioData = useAudioData;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.visualizeAudio = void 0;\nconst get_visualization_1 = require(\"./fft/get-visualization\");\nconst max_value_cached_1 = require(\"./fft/max-value-cached\");\nconst cache = {};\nconst visualizeAudioFrame = ({ audioData: metadata, frame, fps, numberOfSamples, }) => {\n    const cacheKey = metadata.resultId + frame + fps + numberOfSamples;\n    if (cache[cacheKey]) {\n        return cache[cacheKey];\n    }\n    const maxInt = (0, max_value_cached_1.getMaxPossibleMagnitude)(metadata);\n    return (0, get_visualization_1.getVisualization)({\n        sampleSize: numberOfSamples * 2,\n        data: metadata.channelWaveforms[0],\n        frame,\n        fps,\n        sampleRate: metadata.sampleRate,\n        maxInt,\n    });\n};\nconst visualizeAudio = ({ smoothing = true, ...parameters }) => {\n    if (!smoothing) {\n        return visualizeAudioFrame(parameters);\n    }\n    const toSmooth = [\n        parameters.frame - 1,\n        parameters.frame,\n        parameters.frame + 1,\n    ];\n    const all = toSmooth.map((s) => {\n        return visualizeAudioFrame({ ...parameters, frame: s });\n    });\n    return new Array(parameters.numberOfSamples).fill(true).map((_x, i) => {\n        return (new Array(toSmooth.length)\n            .fill(true)\n            .map((_, j) => {\n            return all[j][i];\n        })\n            .reduce((a, b) => a + b, 0) / toSmooth.length);\n    });\n};\nexports.visualizeAudio = visualizeAudio;\n"],"names":[],"sourceRoot":""}